{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "str_list_regex_pattern = r\"'(.*?)'\"\n",
    "\n",
    "# Get the paths to the data\n",
    "data_dir = os.getenv(\"DATA_DIR\")\n",
    "articles_dir = os.path.join(data_dir, \"articles\")\n",
    "\n",
    "# Load the main dataset\n",
    "df = pd.read_csv(f\"{data_dir}/keywords_df.csv\", index_col=0, parse_dates=[1])\n",
    "\n",
    "df[\"Keywords\"].replace(\"[]\", np.nan, inplace=True)\n",
    "df.dropna(subset=[\"Keywords\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to parse target\n",
    "def clean_string(str):\n",
    "    # Make the string lowercase\n",
    "    str = str.lower()\n",
    "    # Remove all non-alphanumeric characters\n",
    "    str = re.sub(r\"[^\\w\\s]\", \"\", str)\n",
    "    # Remove the leading and trailing spaces\n",
    "    return str.strip()\n",
    "\n",
    "def parse_tags(str):\n",
    "    # Split the string on each comma\n",
    "    raw_list = str.split(\",\")\n",
    "    # Clean every string in the list\n",
    "    return list(map(clean_string, raw_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Keywords\"] = df[\"Keywords\"].apply(parse_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequencies_from_lists(dataframe_column):\n",
    "    # Define a dictionary to store the tag frequencies\n",
    "    unique_values = {}\n",
    "\n",
    "    # Loop over the tag values of the dataframe    \n",
    "    for value_list in dataframe_column:\n",
    "        # Loop over each tag in the tag list\n",
    "        for value in value_list:\n",
    "            # If the tag is not in the dictionary, add it\n",
    "            new_frequency = 1\n",
    "            # Attempt to get the tag from the dictionary\n",
    "            current_frequency = unique_values.get(value)\n",
    "            # Check if the tag is in the dictionary\n",
    "            if current_frequency:\n",
    "                # If the tag is in the dictionary, increment the frequency by 1\n",
    "                new_frequency = np.add(current_frequency, 1)\n",
    "            # Set the new value for the tag in the dictionary\n",
    "            unique_values[value] = new_frequency\n",
    "    # Return the dictionary\n",
    "    return unique_values\n",
    "\n",
    "def get_sorted_frequencies_in_dataframe(dataframe_column):\n",
    "    # Get the unique values from the lists in a column\n",
    "    unique_values = get_frequencies_from_lists(dataframe_column)\n",
    "    # Sort the tags by their frequency, from high to low\n",
    "    sorted_unique_tag_frequency = sorted(unique_values.items(), key=lambda x: x[1], reverse=True)\n",
    "    # Convert the list into a dataframe and return it\n",
    "    return pd.DataFrame(sorted_unique_tag_frequency, columns=[dataframe_column.name, \"Frequency\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_keywords = get_sorted_frequencies_in_dataframe(df.Keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if a word occurs in a list of words\n",
    "def list_has_word(l, word):\n",
    "    if word in l:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def custom_keywords_one_hot_encoding(number_of_keywords):\n",
    "    # A dictionary which stores the new columns\n",
    "    one_hot_keyword_columns = {}\n",
    "    # The names of the new keyword columns\n",
    "    keyword_column_names = []\n",
    "    for i in range(0, number_of_keywords):\n",
    "        # The current unique keyword\n",
    "        word = unique_keywords.Keywords[i]\n",
    "        # The new column name\n",
    "        column_name = f\"Keyword_{word}\"\n",
    "        # Add the column name to the list of column names\n",
    "        keyword_column_names.append(column_name)\n",
    "        # Add the new column to the dictionary\n",
    "        one_hot_keyword_columns[column_name] = df[\"Keywords\"].apply(lambda l: list_has_word(l, word))\n",
    "    return pd.DataFrame(one_hot_keyword_columns, columns=keyword_column_names)\n",
    "\n",
    "one_hot_keyword_df = custom_keywords_one_hot_encoding(number_of_keywords=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity_score(target, predictions):\n",
    "    return 1 - recall_score(target, predictions, average=\"weighted\")\n",
    "\n",
    "def get_metrics(target, predictions):\n",
    "    return {\n",
    "        \"recall\": recall_score(target, predictions, average=\"weighted\"),\n",
    "        \"precision\": precision_score(target, predictions, average=\"weighted\"),\n",
    "        \"accuracy\": accuracy_score(target, predictions),\n",
    "        \"specificity\": specificity_score(target, predictions),\n",
    "        \"f1\": f1_score(target, predictions, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "def print_metrics(target, predictions):\n",
    "    metrics = get_metrics(target=target, predictions=predictions)\n",
    "    for metric in metrics:\n",
    "        str_metric = \"{:.2f}\".format(metrics[metric] * 100)+\"%\"\n",
    "        print(f\"{metric}: {str_metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = one_hot_keyword_df\n",
    "y = pd.get_dummies(df[\"Category\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc = dtc.fit(X_train,y_train)\n",
    "y_pred_dtc = dtc.predict(X_test)\n",
    "\n",
    "# Print the metrics of the model performance\n",
    "print_metrics(y_test, y_pred_dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dtc_train = dtc.predict(X_train)\n",
    "\n",
    "# Print the metrics of the model performance\n",
    "print_metrics(y_train, y_pred_dtc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dtc_val = dtc.predict(X_val)\n",
    "\n",
    "# Print the metrics of the model performance\n",
    "print_metrics(y_val, y_pred_dtc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn = knn.fit(X_train,y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Print the metrics of the model performance\n",
    "print_metrics(y_test, y_pred_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc = rfc.fit(X_train,y_train)\n",
    "y_pred_rfc = rfc.predict(X_test)\n",
    "\n",
    "# Print the metrics of the model performance\n",
    "print_metrics(y_test, y_pred_rfc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('3.10.4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc03c57ad7b86a0ef884a1652e2e233be898816187802410f759e457b32a702a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
